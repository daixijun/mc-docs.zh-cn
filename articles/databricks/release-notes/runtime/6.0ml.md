---
ms.topic: conceptual
ms.service: azure-databricks
ms.reviewer: mamccrea
ms.custom: databricksmigration
ms.author: saperla
author: mssaperla
ms.date: 08/10/2020
title: Databricks Runtime 6.0 ML（不受支持）- Azure Databricks
description: 关于由 Apache Spark 提供支持的 Databricks Runtime 6.0 ML 的发行说明。
ms.openlocfilehash: 9e0ae4a872b2fe1c17bc04b2c5cfd62547a2e176
ms.sourcegitcommit: 6b499ff4361491965d02bd8bf8dde9c87c54a9f5
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 11/06/2020
ms.locfileid: "94329113"
---
# <a name="databricks-runtime-60-ml-unsupported"></a>Databricks Runtime 6.0 ML（不受支持）

Databricks 于 2019 年 10 月发布了此映像。

Databricks Runtime 6.0 ML 基于 [Databricks Runtime 6.0（不受支持）](6.0.md)，为机器学习和数据科学提供了随时可用的环境。
用于 ML 的 Databricks Runtime 包含许多常用的机器学习库，包括 TensorFlow、PyTorch、Keras 和 XGBoost。 它还支持使用 Horovod 进行分布式深度学习训练。

有关详细信息，包括有关创建 Databricks Runtime ML 群集的说明，请参阅[用于机器学习的 Databricks Runtime](../../runtime/mlruntime.md#mlruntime)。

## <a name="new-features"></a>新增功能

Databricks Runtime 6.0 ML 是基于 Databricks Runtime 6.0 构建的。 若要了解 Databricks Runtime 6.0 中的新增功能，请参阅 [Databricks Runtime 6.0（不受支持）](6.0.md)发行说明。

### <a name="query-mlflow-experiment-data-at-scale-using-the-new-mlflow-spark-data-source"></a>使用新的 MLflow Spark 数据源大规模查询 MLflow 试验数据

MLflow 试验 Spark 数据源提供了一种用于加载 MLflow 试验运行数据的标准 API。 这样便可使用 DataFrame API 大规模查询和分析 MLflow 试验数据。 对于特定试验，DataFrame 包含 run_ids、指标、参数、标签、start_time、end_time、状态和项目的 artifact_uri。 请参阅 [MLflow 试验](../../data/data-sources/mlflow-experiment.md#mlflow-exp-datasource)。

## <a name="improvements"></a>改进

* Hyperopt 正式版

  Azure Databricks 上的 Hyperopt 现已正式发布。 自公共预览以来的显著改进包括对 Spark 辅助角色上的 MLflow 日志记录的支持、PySpark 广播变量的正确处理，以及使用 Hyperopt 选择模型的新指南。 我们还修复了日志消息、错误处理、UI 中的小错误，使文档更易于阅读。 有关详细信息，请参阅 [Hyperopt 文档](../../applications/machine-learning/automl-hyperparam-tuning/index.md#hyperopt-overview)。

  我们已更新 Azure Databricks 记录 Hyperopt 试验的方式，现在你可以通过将指标传递到 `mlflow.log_metric` 函数（请参阅 [log_metric](https://mlflow.org/docs/latest/python_api/mlflow.tracking.html#mlflow.tracking.MlflowClient.log_metric)）来记录 Hyperopt 运行期间的自定义指标。 如果要记录自定义指标以及损失（默认在调用 `hyperopt.fmin` 函数时记录），这很有用。

* MLflow
  * 添加了 MLflow Java 客户端 1.2.0
  * MLflow 现已提升为顶层[库](../../runtime/mlruntime.md#mllibraries)
* 升级了机器学习库
  * Horovod 已从 0.16.4 升级到 0.18.1
  * MLflow 已从 1.0.0 升级到 1.2.0
* Anaconda 分发已从 5.2.0 升级到 2019.03

## <a name="removal"></a>删除

* 已删除 [Databricks ML 模型导出](../../applications/machine-learning/model-export/model-export-import.md#model-export-import)。 改用 [MLeap](../../applications/machine-learning/model-export/mleap-model-export.md#mleap-model-export) 来导入和导出模型。
* 在 [Hyperopt](../../applications/machine-learning/automl-hyperparam-tuning/index.md#hyperopt-overview) 库中，删除了 `hyperopt.SparkTrials` 的以下属性：
  * `SparkTrials.successful_trials_count`
  * `SparkTrials.failed_trials_count`
  * `SparkTrials.cancelled_trials_count`
  * `SparkTrials.total_trials_count`

  将其替换为以下函数：

  * `SparkTrials.count_successful_trials()`
  * `SparkTrials.count_failed_trials()`
  * `SparkTrials.count_cancelled_trials()`
  * `SparkTrials.count_total_trials()`

## <a name="system-environment"></a>系统环境

Databricks Runtime 6.0 ML 中的系统环境与 Databricks Runtime 6.0 不同，如下所示：

* **DBUtils**：不包含[库实用工具](../../dev-tools/databricks-utils.md#dbutils-library)。

## <a name="libraries"></a><a id="libraries"> </a><a id="mlr60-libraries"> </a>库

以下部分列出了 Databricks Runtime 6.0 ML 中包含的库，这些库不同于 Databricks Runtime 6.0 中包含的库。

### <a name="top-tier-libraries"></a>顶层库

Databricks Runtime 6.0 ML 包含以下顶层[库](../../runtime/mlruntime.md#mllibraries)：

* [GraphFrames](../../spark/latest/graph-analysis/graphframes/index.md)
* [Horovod 和 HorovodRunner](../../applications/machine-learning/train-model/distributed-training/index.md#distributed-training)
* [MLflow](../../applications/mlflow/index.md#mlflow-guide)
* [PyTorch](../../applications/machine-learning/train-model/pytorch.md)
* [spark-tensorflow-connector](../../applications/machine-learning/load-data/tfrecords-save-load.md#df-to-tfrecord)
* [TensorFlow](../../applications/machine-learning/train-model/tensorflow.md#tensorflow1)
* [TensorBoard](../../applications/machine-learning/train-model/tensorflow.md#using-tensorboard)

### <a name="python-libraries"></a>Python 库

Databricks Runtime 6.0 ML 使用 Conda 进行 Python 包管理，并且包含许多常用的 ML 包。 下一部分介绍用于 Databricks Runtime 6.0 ML 的 Conda 环境。

#### <a name="python-3-on-cpu-clusters"></a>CPU 群集上的 Python 3

```yaml
name: databricks-ml
channels:
  - pytorch
  - defaults
dependencies:
  - _libgcc_mutex=0.1=main
  - _py-xgboost-mutex=2.0=cpu_0
  - _tflow_select=2.3.0=mkl
  - absl-py=0.7.1=py37_0
  - asn1crypto=0.24.0=py37_0
  - astor=0.8.0=py37_0
  - backcall=0.1.0=py37_0
  - backports=1.0=py_2
  - bcrypt=3.1.6=py37h7b6447c_0
  - blas=1.0=mkl
  - boto=2.49.0=py37_0
  - boto3=1.9.162=py_0
  - botocore=1.12.163=py_0
  - c-ares=1.15.0=h7b6447c_1001
  - ca-certificates=2019.1.23=0
  - certifi=2019.3.9=py37_0
  - cffi=1.12.2=py37h2e261b9_1
  - chardet=3.0.4=py37_1003
  - click=7.0=py37_0
  - cloudpickle=0.8.0=py37_0
  - colorama=0.4.1=py37_0
  - configparser=3.7.4=py37_0
  - cryptography=2.6.1=py37h1ba5d50_0
  - cycler=0.10.0=py37_0
  - cython=0.29.6=py37he6710b0_0
  - decorator=4.4.0=py37_1
  - docutils=0.14=py37_0
  - entrypoints=0.3=py37_0
  - et_xmlfile=1.0.1=py37_0
  - flask=1.0.2=py37_1
  - freetype=2.9.1=h8a8886c_1
  - future=0.17.1=py37_0
  - gast=0.2.2=py37_0
  - gitdb2=2.0.5=py37_0
  - gitpython=2.1.11=py37_0
  - grpcio=1.16.1=py37hf8bcb03_1
  - gunicorn=19.9.0=py37_0
  - h5py=2.9.0=py37h7918eee_0
  - hdf5=1.10.4=hb1b8bf9_0
  - html5lib=1.0.1=py_0
  - icu=58.2=h9c2bf20_1
  - idna=2.8=py37_0
  - intel-openmp=2019.3=199
  - ipython=7.4.0=py37h39e3cac_0
  - ipython_genutils=0.2.0=py37_0
  - itsdangerous=1.1.0=py37_0
  - jdcal=1.4=py37_0
  - jedi=0.13.3=py37_0
  - jinja2=2.10=py37_0
  - jmespath=0.9.4=py_0
  - jpeg=9b=h024ee3a_2
  - keras=2.2.4=0
  - keras-applications=1.0.8=py_0
  - keras-base=2.2.4=py37_0
  - keras-preprocessing=1.1.0=py_1
  - kiwisolver=1.0.1=py37hf484d3e_0
  - krb5=1.16.1=h173b8e3_7
  - libedit=3.1.20181209=hc058e9b_0
  - libffi=3.2.1=hd88cf55_4
  - libgcc-ng=8.2.0=hdf63c60_1
  - libgfortran-ng=7.3.0=hdf63c60_0
  - libpng=1.6.36=hbc83047_0
  - libpq=11.2=h20c2e04_0
  - libprotobuf=3.8.0=hd408876_0
  - libsodium=1.0.16=h1bed415_0
  - libstdcxx-ng=8.2.0=hdf63c60_1
  - libtiff=4.0.10=h2733197_2
  - libxgboost=0.90=he6710b0_0
  - libxml2=2.9.9=hea5a465_1
  - libxslt=1.1.33=h7d1a2b0_0
  - llvmlite=0.28.0=py37hd408876_0
  - lxml=4.3.2=py37hefd8a0e_0
  - mako=1.0.10=py_0
  - markdown=3.1.1=py37_0
  - markupsafe=1.1.1=py37h7b6447c_0
  - mkl=2019.3=199
  - mkl_fft=1.0.10=py37ha843d7b_0
  - mkl_random=1.0.2=py37hd81dba3_0
  - mock=3.0.5=py37_0
  - ncurses=6.1=he6710b0_1
  - networkx=2.2=py37_1
  - ninja=1.9.0=py37hfd86e86_0
  - nose=1.3.7=py37_2
  - numba=0.43.1=py37h962f231_0
  - numpy=1.16.2=py37h7e9f1db_0
  - numpy-base=1.16.2=py37hde5b4d6_0
  - olefile=0.46=py37_0
  - openpyxl=2.6.1=py37_1
  - openssl=1.1.1b=h7b6447c_1
  - pandas=0.24.2=py37he6710b0_0
  - paramiko=2.4.2=py37_0
  - parso=0.3.4=py37_0
  - pathlib2=2.3.3=py37_0
  - patsy=0.5.1=py37_0
  - pexpect=4.6.0=py37_0
  - pickleshare=0.7.5=py37_0
  - pillow=5.4.1=py37h34e0f95_0
  - pip=19.0.3=py37_0
  - ply=3.11=py37_0
  - prompt_toolkit=2.0.9=py37_0
  - protobuf=3.8.0=py37he6710b0_0
  - psutil=5.6.1=py37h7b6447c_0
  - psycopg2=2.7.6.1=py37h1ba5d50_0
  - ptyprocess=0.6.0=py37_0
  - py-xgboost=0.90=py37he6710b0_0
  - py-xgboost-cpu=0.90=py37_0
  - pyasn1=0.4.6=py_0
  - pycparser=2.19=py37_0
  - pygments=2.3.1=py37_0
  - pymongo=3.8.0=py37he6710b0_1
  - pynacl=1.3.0=py37h7b6447c_0
  - pyopenssl=19.0.0=py37_0
  - pyparsing=2.3.1=py37_0
  - pysocks=1.6.8=py37_0
  - python=3.7.3=h0371630_0
  - python-dateutil=2.8.0=py37_0
  - python-editor=1.0.4=py_0
  - pytorch-cpu=1.1.0=py3.7_cpu_0
  - pytz=2018.9=py37_0
  - pyyaml=5.1=py37h7b6447c_0
  - readline=7.0=h7b6447c_5
  - requests=2.21.0=py37_0
  - s3transfer=0.2.1=py37_0
  - scikit-learn=0.20.3=py37hd81dba3_0
  - scipy=1.2.1=py37h7c811a0_0
  - setuptools=40.8.0=py37_0
  - simplejson=3.16.0=py37h14c3975_0
  - singledispatch=3.4.0.3=py37_0
  - six=1.12.0=py37_0
  - smmap2=2.0.5=py37_0
  - sqlite=3.27.2=h7b6447c_0
  - sqlparse=0.3.0=py_0
  - statsmodels=0.9.0=py37h035aef0_0
  - tabulate=0.8.3=py37_0
  - tensorboard=1.13.1=py37hf484d3e_0
  - tensorflow=1.13.1=mkl_py37h54b294f_0
  - tensorflow-base=1.13.1=mkl_py37h7ce6ba3_0
  - tensorflow-estimator=1.13.0=py_0
  - tensorflow-mkl=1.13.1=h4fcabd2_0
  - termcolor=1.1.0=py37_1
  - tk=8.6.8=hbc83047_0
  - torchvision-cpu=0.3.0=py37_cuNone_1
  - tqdm=4.31.1=py37_1
  - traitlets=4.3.2=py37_0
  - urllib3=1.24.1=py37_0
  - virtualenv=16.0.0=py37_0
  - wcwidth=0.1.7=py37_0
  - webencodings=0.5.1=py37_1
  - websocket-client=0.56.0=py37_0
  - werkzeug=0.14.1=py37_0
  - wheel=0.33.1=py37_0
  - wrapt=1.11.1=py37h7b6447c_0
  - xz=5.2.4=h14c3975_4
  - yaml=0.1.7=had09818_2
  - zlib=1.2.11=h7b6447c_3
  - zstd=1.3.7=h0b5b093_0
  - pip:
    - argparse==1.4.0
    - databricks-cli==0.9.0
    - docker==4.0.2
    - fusepy==2.0.4
    - gorilla==0.3.0
    - horovod==0.18.1
    - hyperopt==0.1.2.db8
    - matplotlib==3.0.3
    - mleap==0.8.1
    - mlflow==1.2.0
    - nose-exclude==0.5.0
    - pyarrow==0.13.0
    - querystring-parser==1.2.4
    - seaborn==0.9.0
    - tensorboardx==1.8
prefix: /databricks/conda/envs/databricks-ml
```

#### <a name="spark-packages-containing-python-modules"></a>包含 Python 模块的 Spark 包

| Spark 包                     | Python 模块                     | 版本                           |
|-----------------------------------|-----------------------------------|-----------------------------------|
| graphframes                       | graphframes                       | 0.7.0-db1-spark2.4                |
| spark-deep-learning               | sparkdl                           | 1.5.0-db5-spark2.4                |
| tensorframes                      | tensorframes                      | 0.7.0-s_2.11                      |

### <a name="r-libraries"></a>R 库

R 库与 [Databricks Runtime 6.0 中的 R 库](6.0.md#rlibraries60)完全相同。

### <a name="java-and-scala-libraries-scala-211-cluster"></a>Java 库和 Scala 库（Scala 2.11 群集）

除了 Databricks Runtime 6.0 中的 Java 库和 Scala 库之外，Databricks Runtime 6.0 ML 还包含以下 JAR：

| 组 ID                          | 项目 ID                       | 版本                           |
|-----------------------------------|-----------------------------------|-----------------------------------|
| com.databricks                    | spark-deep-learning               | 1.5.0-db5-spark2.4                |
| com.typesafe.akka                 | akka-actor_2.11                   | 2.3.11                            |
| ml.combust.mleap                  | mleap-databricks-runtime_2.11     | 0.14.0                            |
| ml.dmlc                           | xgboost4j                         | 0.90                              |
| ml.dmlc                           | xgboost4j-spark                   | 0.90                              |
| org.graphframes                   | graphframes_2.11                  | 0.7.0-db1-spark2.4                |
| org.mlflow                        | mlflow-client                     | 1.2.0                             |
| org.tensorflow                    | libtensorflow                     | 1.13.1                            |
| org.tensorflow                    | libtensorflow_jni                 | 1.13.1                            |
| org.tensorflow                    | spark-tensorflow-connector_2.11   | 1.13.1                            |
| org.tensorflow                    | tensorflow                        | 1.13.1                            |
| org.tensorframes                  | tensorframes                      | 0.7.0-s_2.11                      |